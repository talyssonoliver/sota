#!/usr/bin/env python3
"""
Task Report Generation Script for Phase 6 - Enhanced End-of-Day Reporting

Extended script for generating enhanced end-of-day reports with velocity tracking,
tomorrow's preparation, sprint health indicators, and visual progress summaries.
This implements Phase 6 Step 6.3 requirements following TDD methodology.

API Documentation:
=================

Main Functions:
---------------

generate_end_of_day_report(day: int) -> bool:
    Generates comprehensive end-of-day report with velocity tracking, tomorrow's 
    preparation, sprint health indicators, and visual progress summaries.
    
    Args:
        day: Sprint day number (1-based)
    
    Returns:
        bool: True if report generation succeeded, False otherwise
    
    Example:
        >>> generate_end_of_day_report(2)
        True

generate_daily_report(day: int) -> bool:
    Generates traditional daily progress report with task summaries and QA metrics.
    
    Args:
        day: Sprint day number (1-based)
    
    Returns:
        bool: True if report generation succeeded, False otherwise

generate_task_specific_report(task_id: str) -> bool:
    Generates detailed report for a specific task including metrics and status.
    
    Args:
        task_id: Task identifier (e.g., "BE-01", "FE-03")
    
    Returns:
        bool: True if report generation succeeded, False otherwise

update_dashboard(task_id: Optional[str] = None) -> bool:
    Updates completion dashboard with latest metrics and optionally marks task green.
    
    Args:
        task_id: Optional task ID to mark as completed
    
    Returns:
        bool: True if dashboard update succeeded, False otherwise

Velocity Analysis Functions:
---------------------------

_calculate_sprint_velocity(progress_generator, target_date) -> Dict[str, Any]:
    Calculates current sprint velocity with trend analysis over 7-day window.
    
    Returns:
        Dict containing:
        - current_velocity: float (tasks/day)
        - trend: str ("increasing", "decreasing", "stable")
        - velocity_history: List[Dict] (7-day history)
        - sprint_burn_rate: float (percentage)
        - projected_completion: float (percentage)

_analyze_tomorrow_preparation(progress_generator, target_date) -> Dict[str, Any]:
    Analyzes tomorrow's task priorities, blockers, and preparation requirements.
    
    Returns:
        Dict containing:
        - total_planned: int (number of planned tasks)
        - high_priority: int (high priority task count)
        - priority_tasks: List[Dict] (top 5 priority tasks)
        - potential_blockers: List[Dict] (identified blockers)
        - preparation_checklist: List[str] (preparation items)

_assess_sprint_health(progress_generator) -> Dict[str, Any]:
    Assesses overall sprint health with comprehensive health indicators.
    
    Returns:
        Dict containing:
        - overall_score: float (0-100 health score)
        - status: str ("excellent", "good", "needs_attention", "critical")
        - completion_rate: float (percentage)
        - qa_pass_rate: float (percentage)
        - velocity_consistency: float (percentage)
        - recommendations: List[str] (actionable recommendations)

Visual Reporting Functions:
--------------------------

_generate_visual_progress_summary(progress_generator, velocity_data) -> str:
    Generates ASCII charts and visual progress indicators for enhanced reporting.
    
    Returns:
        str: Markdown-formatted visual summary with progress bars and charts

_create_enhanced_eod_report(day, target_date, daily_report, velocity_data, 
                           tomorrow_prep, sprint_health, visual_summary) -> str:
    Creates comprehensive enhanced end-of-day report combining all analysis sections.
    
    Returns:
        str: Complete enhanced EOD report in Markdown format

Helper Functions:
----------------

_get_tasks_for_date(task_metrics, date) -> List[Dict[str, Any]]:
    Filters task metrics for specific completion date.

_calculate_velocity_score(tasks) -> float:
    Calculates weighted velocity score based on task complexity and quality.

_calculate_burn_rate(task_metrics) -> float:
    Calculates sprint burn rate as percentage of completed tasks.

_project_sprint_completion(metrics, current_velocity) -> float:
    Projects sprint completion percentage based on current velocity trends.

CLI Usage:
---------

python scripts/generate_task_report.py --day 2                 # Enhanced EOD report
python scripts/generate_task_report.py --daily 2               # Traditional daily report  
python scripts/generate_task_report.py --task BE-07            # Task-specific report
python scripts/generate_task_report.py --dashboard            # Update dashboard only
python scripts/generate_task_report.py --all                  # Generate all reports

Configuration Options:
---------------------
--format {markdown,console,html}  # Output format
--output-dir DIR                   # Output directory (default: progress_reports)
--verbose, -v                      # Enable verbose output

Integration Points:
------------------
- ProgressReportGenerator: Base daily reporting infrastructure
- EndOfDayReportGenerator: Enhanced EOD report framework  
- CompletionMetricsCalculator: Team and task metrics calculation
- DashboardUpdater: Completion dashboard management

File Output Locations:
---------------------
- Enhanced EOD reports: progress_reports/day{N}_eod_report_{date}.md
- Daily reports: progress_reports/day{N}_report_{date}.md
- Task reports: progress_reports/task_{id}_report_{timestamp}.md

Dependencies:
------------
- scripts.update_dashboard: Dashboard updating functionality
- scripts.generate_progress_report: Base progress reporting
- orchestration.end_of_day_report: Enhanced EOD framework

Error Handling:
--------------
All main functions return boolean success indicators and handle exceptions gracefully.
Detailed error messages are provided for debugging and user feedback.

Performance Considerations:
--------------------------
- Metrics calculations are cached within generator instances
- File I/O operations include proper error handling and encoding
- Large datasets are processed incrementally where possible

Version: Phase 6 Step 6.3 Implementation
Author: AI Agent System Daily Automation
"""

import argparse
import sys
from datetime import datetime, date, timedelta
from pathlib import Path
from typing import Optional, Dict, Any, List

# Add project root to path for imports
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from scripts.update_dashboard import DashboardUpdater
from scripts.generate_progress_report import ProgressReportGenerator
from orchestration.end_of_day_report import EndOfDayReportGenerator


def update_dashboard(task_id: Optional[str] = None) -> bool:
    """Update dashboard with latest completion metrics"""
    print("ğŸ”„ Updating dashboard...")
    
    updater = DashboardUpdater()
    result = updater.update_completion_dashboard(task_id)
    
    if result:
        print("âœ… Dashboard updated successfully")
        print("   ğŸ“Š Completion metrics refreshed")
        print("   ğŸ“ˆ QA coverage trends updated") 
        if task_id:
            print(f"   âœ… {task_id} marked green")
    else:
        print("âŒ Dashboard update failed")
    
    return result


def generate_daily_report(day: int) -> bool:
    """Generate daily progress report"""
    print(f"ğŸ“‹ Generating daily report for day {day}...")
    
    generator = ProgressReportGenerator()
    
    # Calculate target date based on day number
    start_date = date(2025, 4, 1)  # Project start date
    target_date = start_date + timedelta(days=day - 1)
    
    try:
        # Generate daily report
        report_content = generator.generate_daily_report(target_date.strftime('%Y-%m-%d'))
        
        # Save to progress_reports directory
        reports_dir = Path("progress_reports")
        reports_dir.mkdir(exist_ok=True)
        
        report_file = reports_dir / f"day{day}_report_{target_date.strftime('%Y-%m-%d')}.md"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"âœ… Daily report generated: {report_file}")
        print("   ğŸ“Š Summary of completed tasks")
        print("   ğŸ§ª QA metrics included")
        print("   âš ï¸ Blockers and plan adjustments identified")
        
        return True
        
    except Exception as e:
        print(f"âŒ Daily report generation failed: {e}")
        return False


def generate_task_specific_report(task_id: str) -> bool:
    """Generate report for specific task"""
    print(f"ğŸ“‹ Generating report for task {task_id}...")
    
    generator = ProgressReportGenerator()
    
    try:
        # Generate task-specific report
        report_content = generator.generate_task_report(task_id)
        
        # Save to progress_reports directory
        reports_dir = Path("progress_reports")
        reports_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_file = reports_dir / f"task_{task_id}_report_{timestamp}.md"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"âœ… Task report generated: {report_file}")
        return True
        
    except Exception as e:
        print(f"âŒ Task report generation failed: {e}")
        return False


def generate_end_of_day_report(day: int) -> bool:
    """Generate enhanced end-of-day report with velocity tracking and tomorrow's preparation"""
    print(f"ğŸŒ… Generating enhanced end-of-day report for day {day}...")
    
    # Calculate target date based on day number
    start_date = date(2025, 4, 1)  # Project start date
    target_date = start_date + timedelta(days=day - 1)
    
    try:
        # Initialize generators
        progress_generator = ProgressReportGenerator()
        eod_generator = EndOfDayReportGenerator()
        
        # Generate traditional daily report first
        print("   ğŸ“‹ Generating base daily report...")
        daily_report = progress_generator.generate_daily_report(target_date.strftime('%Y-%m-%d'))
        
        # Calculate sprint velocity and trends
        print("   ğŸ“ˆ Calculating sprint velocity and trends...")
        velocity_data = _calculate_sprint_velocity(progress_generator, target_date)
        
        # Analyze tomorrow's preparation
        print("   ğŸ”® Preparing tomorrow's task analysis...")
        tomorrow_prep = _analyze_tomorrow_preparation(progress_generator, target_date)
        
        # Assess sprint health
        print("   ğŸ¥ Assessing sprint health indicators...")
        sprint_health = _assess_sprint_health(progress_generator)
        
        # Generate visual progress summary
        print("   ğŸ“Š Creating visual progress summary...")
        visual_summary = _generate_visual_progress_summary(progress_generator, velocity_data)
        
        # Create enhanced end-of-day report content
        enhanced_report = _create_enhanced_eod_report(
            day, target_date, daily_report, velocity_data, 
            tomorrow_prep, sprint_health, visual_summary
        )
        
        # Save enhanced report
        reports_dir = Path("progress_reports")
        reports_dir.mkdir(exist_ok=True)
        
        eod_report_file = reports_dir / f"day{day}_eod_report_{target_date.strftime('%Y-%m-%d')}.md"
        
        with open(eod_report_file, 'w', encoding='utf-8') as f:
            f.write(enhanced_report)
        
        print(f"âœ… Enhanced end-of-day report generated: {eod_report_file}")
        print("   ğŸš€ Sprint velocity tracking included")
        print("   ğŸ“… Tomorrow's preparation ready")
        print("   ğŸ¯ Sprint health indicators analyzed")
        print("   ğŸ“ˆ Visual progress summaries created")
        
        return True
        
    except Exception as e:
        print(f"âŒ Enhanced end-of-day report generation failed: {e}")
        return False


def _calculate_sprint_velocity(progress_generator: ProgressReportGenerator, target_date: date) -> Dict[str, Any]:
    """Calculate sprint velocity and trend analysis."""
    try:
        metrics = progress_generator.metrics_calculator.calculate_all_metrics()
        task_metrics = metrics.get("task_metrics", [])
        
        # Calculate daily velocity for the past 7 days
        velocity_history = []
        for i in range(7):
            check_date = target_date - timedelta(days=i)
            daily_tasks = _get_tasks_for_date(task_metrics, check_date.strftime('%Y-%m-%d'))
            velocity_history.append({
                "date": check_date.strftime('%Y-%m-%d'),
                "tasks_completed": len(daily_tasks),
                "velocity_score": _calculate_velocity_score(daily_tasks)
            })
        
        # Calculate trend
        recent_velocity = sum(day["tasks_completed"] for day in velocity_history[:3]) / 3
        older_velocity = sum(day["tasks_completed"] for day in velocity_history[4:]) / 3
        
        trend = "increasing" if recent_velocity > older_velocity * 1.1 else \
                "decreasing" if recent_velocity < older_velocity * 0.9 else "stable"
        
        return {
            "current_velocity": recent_velocity,
            "trend": trend,
            "velocity_history": velocity_history,
            "sprint_burn_rate": _calculate_burn_rate(task_metrics),
            "projected_completion": _project_sprint_completion(metrics, recent_velocity)
        }
    except Exception as e:
        print(f"âš ï¸ Error calculating velocity: {e}")
        return {"current_velocity": 0, "trend": "unknown", "velocity_history": []}


def _analyze_tomorrow_preparation(progress_generator: ProgressReportGenerator, target_date: date) -> Dict[str, Any]:
    """Analyze and prepare tomorrow's task priorities and blockers."""
    try:
        metrics = progress_generator.metrics_calculator.calculate_all_metrics()
        
        # Identify planned tasks (simplified - in real system would check task scheduling)
        tomorrow_tasks = _get_planned_tasks_for_tomorrow(metrics, target_date)
        
        # Prioritize tasks based on dependencies and urgency
        priority_tasks = _prioritize_tomorrow_tasks(tomorrow_tasks)
        
        # Identify potential blockers
        potential_blockers = _identify_potential_blockers(metrics)
        
        # Generate preparation checklist
        preparation_checklist = _generate_preparation_checklist(priority_tasks, potential_blockers)
        
        return {
            "total_planned": len(tomorrow_tasks),
            "high_priority": len([t for t in priority_tasks if t.get("priority") == "HIGH"]),
            "priority_tasks": priority_tasks[:5],  # Top 5 priorities
            "potential_blockers": potential_blockers,
            "preparation_checklist": preparation_checklist,
            "resource_requirements": _analyze_resource_requirements(tomorrow_tasks)
        }
    except Exception as e:
        print(f"âš ï¸ Error analyzing tomorrow's preparation: {e}")
        return {"total_planned": 0, "high_priority": 0, "priority_tasks": []}


def _assess_sprint_health(progress_generator: ProgressReportGenerator) -> Dict[str, Any]:
    """Assess overall sprint health with comprehensive indicators."""
    try:
        team_metrics = progress_generator.metrics_calculator.calculate_team_metrics()
        sprint_metrics = progress_generator.metrics_calculator.calculate_sprint_metrics()
        
        # Calculate health score based on multiple factors
        completion_rate = team_metrics.get("completion_rate", 0)
        qa_pass_rate = team_metrics.get("qa_pass_rate", 0)
        velocity_consistency = _calculate_velocity_consistency(progress_generator)
        blocker_impact = _assess_blocker_impact(team_metrics)
        
        # Overall health score (0-100)
        health_score = (completion_rate * 0.4 + qa_pass_rate * 0.3 + 
                       velocity_consistency * 0.2 + (100 - blocker_impact) * 0.1)
        
        # Determine health status
        if health_score >= 80:
            status = "excellent"
        elif health_score >= 60:
            status = "good"
        elif health_score >= 40:
            status = "needs_attention"
        else:
            status = "critical"
        
        return {
            "overall_score": health_score,
            "status": status,
            "completion_rate": completion_rate,
            "qa_pass_rate": qa_pass_rate,
            "velocity_consistency": velocity_consistency,
            "blocker_impact": blocker_impact,
            "recommendations": _generate_health_recommendations(health_score, team_metrics),
            "risk_factors": _identify_risk_factors(team_metrics, sprint_metrics)
        }
    except Exception as e:
        print(f"âš ï¸ Error assessing sprint health: {e}")
        return {"overall_score": 0, "status": "unknown"}


def _generate_visual_progress_summary(progress_generator: ProgressReportGenerator, velocity_data: Dict[str, Any]) -> str:
    """Generate visual ASCII charts and progress indicators."""
    try:
        metrics = progress_generator.metrics_calculator.calculate_all_metrics()
        team_metrics = metrics.get("team_metrics", {})
        
        # Progress bar for completion rate
        completion_rate = team_metrics.get("completion_rate", 0)
        progress_bar = _create_progress_bar(completion_rate, 50)
        
        # Velocity trend chart (simplified ASCII)
        velocity_chart = _create_velocity_chart(velocity_data.get("velocity_history", []))
        
        # Sprint health indicator
        health_indicator = _create_health_indicator(team_metrics)
        
        visual_summary = f"""
## ğŸ“Š Visual Progress Summary

### Sprint Completion Progress
{progress_bar}
**{completion_rate:.1f}% Complete** ({team_metrics.get('completed_tasks', 0)}/{team_metrics.get('total_tasks', 0)} tasks)

### 7-Day Velocity Trend
{velocity_chart}

### Sprint Health Dashboard
{health_indicator}

### QA Quality Metrics
- **Pass Rate:** {team_metrics.get('qa_pass_rate', 0):.1f}% {'ğŸŸ¢' if team_metrics.get('qa_pass_rate', 0) >= 80 else 'ğŸŸ¡' if team_metrics.get('qa_pass_rate', 0) >= 60 else 'ğŸ”´'}
- **Coverage:** {team_metrics.get('average_coverage', 0):.1f}% {'ğŸŸ¢' if team_metrics.get('average_coverage', 0) >= 85 else 'ğŸŸ¡' if team_metrics.get('average_coverage', 0) >= 70 else 'ğŸ”´'}
"""
        
        return visual_summary
    except Exception as e:
        print(f"âš ï¸ Error generating visual summary: {e}")
        return "## ğŸ“Š Visual Progress Summary\n\n*Error generating visual elements*"


def _create_enhanced_eod_report(day: int, target_date: date, daily_report: str, 
                              velocity_data: Dict[str, Any], tomorrow_prep: Dict[str, Any],
                              sprint_health: Dict[str, Any], visual_summary: str) -> str:
    """Create the comprehensive enhanced end-of-day report."""
    
    report_header = f"""# ğŸŒ… Enhanced End-of-Day Report - Day {day}
**Date:** {target_date.strftime('%A, %B %d, %Y')} ({target_date.strftime('%Y-%m-%d')})
**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

---

"""
    
    # Sprint velocity section
    velocity_section = f"""
## ğŸš€ Sprint Velocity Analysis

**Current Velocity:** {velocity_data.get('current_velocity', 0):.1f} tasks/day
**Trend:** {velocity_data.get('trend', 'unknown').title()} {'ğŸ“ˆ' if velocity_data.get('trend') == 'increasing' else 'ğŸ“‰' if velocity_data.get('trend') == 'decreasing' else 'â¡ï¸'}
**Sprint Burn Rate:** {velocity_data.get('sprint_burn_rate', 0):.1f}%
**Projected Completion:** {velocity_data.get('projected_completion', 0):.1f}%

### Velocity History (Last 7 Days)
"""
    
    for day_data in velocity_data.get('velocity_history', [])[:7]:
        velocity_section += f"- **{day_data['date']}**: {day_data['tasks_completed']} tasks (Score: {day_data.get('velocity_score', 0):.1f})\n"
    
    # Tomorrow's preparation section
    tomorrow_section = f"""
## ğŸ“… Tomorrow's Preparation

**Total Planned Tasks:** {tomorrow_prep.get('total_planned', 0)}
**High Priority Tasks:** {tomorrow_prep.get('high_priority', 0)}

### ğŸ¯ Top Priority Tasks
"""
    
    for task in tomorrow_prep.get('priority_tasks', []):
        tomorrow_section += f"- **{task.get('id', 'Unknown')}**: {task.get('title', 'No title')} (Priority: {task.get('priority', 'MEDIUM')})\n"
    
    tomorrow_section += f"""
### âš ï¸ Potential Blockers
"""
    for blocker in tomorrow_prep.get('potential_blockers', []):
        tomorrow_section += f"- {blocker.get('description', 'Unknown blocker')} (Impact: {blocker.get('impact', 'LOW')})\n"
    
    tomorrow_section += f"""
### âœ… Preparation Checklist
"""
    for item in tomorrow_prep.get('preparation_checklist', []):
        tomorrow_section += f"- [ ] {item}\n"
    
    # Sprint health section
    health_section = f"""
## ğŸ¥ Sprint Health Status

**Overall Health Score:** {sprint_health.get('overall_score', 0):.1f}/100
**Status:** {sprint_health.get('status', 'unknown').title().replace('_', ' ')} {'ğŸŸ¢' if sprint_health.get('status') == 'excellent' else 'ğŸŸ¡' if sprint_health.get('status') == 'good' else 'ğŸŸ ' if sprint_health.get('status') == 'needs_attention' else 'ğŸ”´'}

### Health Metrics
- **Completion Rate:** {sprint_health.get('completion_rate', 0):.1f}%
- **QA Pass Rate:** {sprint_health.get('qa_pass_rate', 0):.1f}%
- **Velocity Consistency:** {sprint_health.get('velocity_consistency', 0):.1f}%
- **Blocker Impact:** {sprint_health.get('blocker_impact', 0):.1f}%

### ğŸ“‹ Recommendations
"""
    
    for rec in sprint_health.get('recommendations', []):
        health_section += f"- {rec}\n"
    
    # Combine all sections
    enhanced_report = (
        report_header +
        velocity_section +
        tomorrow_section +
        health_section +
        visual_summary +
        "\n---\n\n" +
        "## ğŸ“‹ Base Daily Report\n\n" +
        daily_report +
        f"\n\n---\n*Enhanced End-of-Day Report generated by Phase 6 Daily Automation System*"
    )
    
    return enhanced_report


# Helper functions for calculations and analysis

def _get_tasks_for_date(task_metrics: List[Dict[str, Any]], date: str) -> List[Dict[str, Any]]:
    """Get tasks completed on specific date."""
    tasks = []
    for task in task_metrics:
        if task.get("completion_time"):
            try:
                completion_time = datetime.fromisoformat(task["completion_time"].replace('Z', '+00:00'))
                completion_date = completion_time.strftime('%Y-%m-%d')
                if completion_date == date:
                    tasks.append(task)
            except Exception:
                continue
    return tasks


def _calculate_velocity_score(tasks: List[Dict[str, Any]]) -> float:
    """Calculate velocity score based on task complexity and quality."""
    if not tasks:
        return 0.0
    
    total_score = 0
    for task in tasks:
        base_score = 1.0
        
        # Bonus for QA pass
        if task.get("qa_status") == "PASSED":
            base_score += 0.5
        
        # Bonus for high coverage
        coverage = task.get("coverage", 0)
        if coverage >= 90:
            base_score += 0.3
        elif coverage >= 80:
            base_score += 0.1
        
        total_score += base_score
    
    return total_score


def _calculate_burn_rate(task_metrics: List[Dict[str, Any]]) -> float:
    """Calculate sprint burn rate."""
    completed_tasks = len([t for t in task_metrics if t.get("status") == "COMPLETED"])
    total_tasks = len(task_metrics)
    return (completed_tasks / total_tasks * 100) if total_tasks > 0 else 0


def _project_sprint_completion(metrics: Dict[str, Any], current_velocity: float) -> float:
    """Project sprint completion percentage."""
    team_metrics = metrics.get("team_metrics", {})
    remaining_tasks = team_metrics.get("total_tasks", 0) - team_metrics.get("completed_tasks", 0)
    
    if current_velocity > 0:
        days_remaining = remaining_tasks / current_velocity
        # Assume 14-day sprint (simplified)
        completion_projection = min(100, (14 - days_remaining) / 14 * 100)
        return max(0, completion_projection)
    
    return team_metrics.get("completion_rate", 0)


def _get_planned_tasks_for_tomorrow(metrics: Dict[str, Any], target_date: date) -> List[Dict[str, Any]]:
    """Get planned tasks for tomorrow (simplified implementation)."""
    # In a real system, this would query a task scheduling system
    # For now, return tasks that are IN_PROGRESS or CREATED
    task_metrics = metrics.get("task_metrics", [])
    planned_tasks = []
    
    for task in task_metrics:
        if task.get("status") in ["IN_PROGRESS", "CREATED", "PLANNED"]:
            planned_tasks.append({
                "id": task.get("task_id", "Unknown"),
                "title": f"Task {task.get('task_id', 'Unknown')} - {task.get('agent_type', 'unknown')} work",
                "priority": "HIGH" if task.get("agent_type") == "backend" else "MEDIUM",
                "estimated_duration": "2-4 hours"
            })
    
    return planned_tasks[:10]  # Limit to reasonable number


def _prioritize_tomorrow_tasks(tasks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """Prioritize tomorrow's tasks based on various factors."""
    # Sort by priority, then by estimated impact
    priority_order = {"HIGH": 3, "MEDIUM": 2, "LOW": 1}
    return sorted(tasks, key=lambda t: priority_order.get(t.get("priority", "LOW"), 1), reverse=True)


def _identify_potential_blockers(metrics: Dict[str, Any]) -> List[Dict[str, Any]]:
    """Identify potential blockers for tomorrow."""
    blockers = []
    
    team_metrics = metrics.get("team_metrics", {})
    
    # Check for low QA pass rate
    if team_metrics.get("qa_pass_rate", 0) < 70:
        blockers.append({
            "description": "Low QA pass rate may slow down task completion",
            "impact": "MEDIUM",
            "mitigation": "Review QA processes and provide additional testing support"
        })
    
    # Check for low test coverage
    if team_metrics.get("average_coverage", 0) < 80:
        blockers.append({
            "description": "Low test coverage may cause deployment issues",
            "impact": "HIGH",
            "mitigation": "Prioritize test writing and coverage improvement"
        })
    
    return blockers


def _generate_preparation_checklist(priority_tasks: List[Dict[str, Any]], blockers: List[Dict[str, Any]]) -> List[str]:
    """Generate preparation checklist for tomorrow."""
    checklist = [
        "Review tomorrow's priority tasks and dependencies",
        "Ensure development environment is updated and ready",
        "Check for any pending code reviews or approvals"
    ]
    
    if priority_tasks:
        checklist.append(f"Prepare resources for {len(priority_tasks)} priority tasks")
    
    if blockers:
        checklist.append("Address identified potential blockers")
        for blocker in blockers:
            checklist.append(f"  - {blocker.get('mitigation', 'Address blocker')}")
    
    checklist.extend([
        "Validate all development tools and dependencies",
        "Schedule any required team coordination or reviews"
    ])
    
    return checklist


def _analyze_resource_requirements(tasks: List[Dict[str, Any]]) -> Dict[str, Any]:
    """Analyze resource requirements for tomorrow's tasks."""
    return {
        "estimated_hours": len(tasks) * 3,  # Simplified estimation
        "team_coordination_needed": len(tasks) > 5,
        "review_bandwidth_required": True,
        "testing_resources_needed": len(tasks) > 3
    }


def _calculate_velocity_consistency(progress_generator: ProgressReportGenerator) -> float:
    """Calculate velocity consistency score."""
    # Simplified implementation - in real system would analyze velocity variance
    return 75.0  # Placeholder - would calculate from historical data


def _assess_blocker_impact(team_metrics: Dict[str, Any]) -> float:
    """Assess the impact of current blockers."""
    # Simplified implementation - would analyze actual blocked tasks
    failed_tasks = team_metrics.get("failed_tasks", 0)
    total_tasks = team_metrics.get("total_tasks", 1)
    return (failed_tasks / total_tasks * 100)


def _generate_health_recommendations(health_score: float, team_metrics: Dict[str, Any]) -> List[str]:
    """Generate recommendations based on sprint health."""
    recommendations = []
    
    if health_score < 60:
        recommendations.append("ğŸš¨ Critical: Immediate attention needed to sprint health")
    
    if team_metrics.get("qa_pass_rate", 0) < 80:
        recommendations.append("ğŸ“ Focus on improving QA processes and test quality")
    
    if team_metrics.get("completion_rate", 0) < 70:
        recommendations.append("âš¡ Consider re-prioritizing tasks or adding resources")
    
    if team_metrics.get("average_coverage", 0) < 85:
        recommendations.append("ğŸ§ª Invest in improving test coverage across all tasks")
    
    if not recommendations:
        recommendations.append("âœ… Sprint health is good - maintain current practices")
    
    return recommendations


def _identify_risk_factors(team_metrics: Dict[str, Any], sprint_metrics: Dict[str, Any]) -> List[str]:
    """Identify risk factors for the sprint."""
    risks = []
    
    if team_metrics.get("completion_rate", 0) < 50:
        risks.append("Low completion rate may jeopardize sprint goals")
    
    if team_metrics.get("qa_pass_rate", 0) < 70:
        risks.append("Quality issues may impact delivery timeline")
    
    if team_metrics.get("failed_tasks", 0) > 2:
        risks.append("High number of failed tasks indicates process issues")
    
    return risks


def _create_progress_bar(percentage: float, width: int = 50) -> str:
    """Create ASCII progress bar."""
    filled = int(width * percentage / 100)
    bar = "â–ˆ" * filled + "â–‘" * (width - filled)
    return f"[{bar}] {percentage:.1f}%"


def _create_velocity_chart(velocity_history: List[Dict[str, Any]]) -> str:
    """Create simple ASCII velocity chart."""
    if not velocity_history:
        return "No velocity data available"
    
    chart = "```\n"
    max_tasks = max(day.get("tasks_completed", 0) for day in velocity_history) or 1
    
    for day in reversed(velocity_history):  # Most recent first
        tasks = day.get("tasks_completed", 0)
        bar_length = int(tasks / max_tasks * 20)
        bar = "â–“" * bar_length + "â–‘" * (20 - bar_length)
        chart += f"{day['date'][-5:]} |{bar}| {tasks} tasks\n"
    
    chart += "```"
    return chart


def _create_health_indicator(team_metrics: Dict[str, Any]) -> str:
    """Create sprint health visual indicator."""
    completion_rate = team_metrics.get("completion_rate", 0)
    qa_pass_rate = team_metrics.get("qa_pass_rate", 0)
    
    indicators = []
    
    # Completion indicator
    if completion_rate >= 80:
        indicators.append("ğŸŸ¢ Completion: Excellent")
    elif completion_rate >= 60:
        indicators.append("ğŸŸ¡ Completion: Good")
    else:
        indicators.append("ğŸ”´ Completion: Needs Attention")
    
    # Quality indicator
    if qa_pass_rate >= 90:
        indicators.append("ğŸŸ¢ Quality: Excellent")
    elif qa_pass_rate >= 70:
        indicators.append("ğŸŸ¡ Quality: Good")
    else:
        indicators.append("ğŸ”´ Quality: Needs Attention")
    
    return "\n".join(indicators)


def main():
    """Main CLI interface for task report generation."""
    parser = argparse.ArgumentParser(
        description="Enhanced Task Report Generator for Phase 6 Daily Automation",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python scripts/generate_task_report.py --day 2                 # Generate enhanced end-of-day report for day 2
  python scripts/generate_task_report.py --daily 2               # Generate traditional daily report for day 2  
  python scripts/generate_task_report.py --task BE-07            # Generate task-specific report
  python scripts/generate_task_report.py --dashboard            # Update dashboard only
        """
    )
    
    # Command options
    parser.add_argument("--day", type=int, help="Generate enhanced end-of-day report for specified day")
    parser.add_argument("--daily", type=int, help="Generate traditional daily report for specified day")
    parser.add_argument("--task", type=str, help="Generate report for specific task ID")
    parser.add_argument("--dashboard", action="store_true", help="Update dashboard with latest metrics")
    parser.add_argument("--all", action="store_true", help="Generate all reports (daily + EOD)")
    
    # Configuration options
    parser.add_argument("--format", choices=["markdown", "console", "html"], 
                       default="markdown", help="Output format for reports")
    parser.add_argument("--output-dir", default="progress_reports", 
                       help="Output directory for reports")
    parser.add_argument("--verbose", "-v", action="store_true", 
                       help="Enable verbose output")
    
    args = parser.parse_args()
    
    # Validate arguments
    if not any([args.day, args.daily, args.task, args.dashboard, args.all]):
        parser.error("Must specify one of: --day, --daily, --task, --dashboard, or --all")
    
    success = True
    
    try:
        if args.verbose:
            print("ğŸš€ Enhanced Task Report Generator - Phase 6")
            print("=" * 50)
        
        # Generate enhanced end-of-day report
        if args.day:
            success &= generate_end_of_day_report(args.day)
        
        # Generate traditional daily report
        if args.daily:
            success &= generate_daily_report(args.daily)
        
        # Generate task-specific report
        if args.task:
            success &= generate_task_specific_report(args.task)
        
        # Update dashboard
        if args.dashboard:
            success &= update_dashboard()
        
        # Generate all reports
        if args.all:
            # Default to current day for all reports
            current_day = (date.today() - date(2025, 4, 1)).days + 1
            success &= generate_daily_report(current_day)
            success &= generate_end_of_day_report(current_day)
            success &= update_dashboard()
        
        if success:
            print("\nâœ… All operations completed successfully!")
            if args.verbose:
                print("   ğŸ“Š Reports available in progress_reports/ directory")
                print("   ğŸ¯ Dashboard updated with latest metrics")
        else:
            print("\nâŒ Some operations failed - check output above")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\nâš ï¸ Operation cancelled by user")
        sys.exit(130)
    except Exception as e:
        print(f"\nâŒ Unexpected error: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
